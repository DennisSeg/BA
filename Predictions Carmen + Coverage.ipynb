{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict geolocation with Carmen\n",
    "import json\n",
    "import carmen\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Method returns prediction\n",
    "def getLocation(data):\n",
    "    \n",
    "    tweet = json.loads(data)\n",
    "    \n",
    "    # Carmen \n",
    "    resolver = carmen.get_resolver()\n",
    "    resolver.load_locations()\n",
    "    location = resolver.resolve_tweet(tweet)\n",
    "    \n",
    "    # If Carmen can predict -> location == True\n",
    "    if location:\n",
    "        return({\"id\": tweet[\"id\"],\n",
    "                        \"latitude\": location[1].latitude,\n",
    "                        \"longitude\": location[1].longitude,\n",
    "                        \"country\": location[1].country,\n",
    "                        \"state\": location[1].state,\n",
    "                        \"county\": location[1].county,\n",
    "                        \"city\": location[1].city,\n",
    "                        \"known\": location[1].known, # True if location appears in Database, false otherwise\n",
    "                        \"location_id\": location[1].id}) # Location based solely on Twitter Place Information\n",
    "    \n",
    "    \n",
    "    # If Carmen can't predict, we set all attributes to \"None\"\n",
    "    else:\n",
    "        return({\"id\": tweet[\"id\"],\n",
    "                        \"latitude\": \"None\",\n",
    "                        \"longitude\": \"None\",\n",
    "                        \"country\": \"None\",\n",
    "                        \"state\": \"None\",\n",
    "                        \"county\": \"None\",\n",
    "                        \"city\": \"None\",\n",
    "                        \"known\": \"None\",\n",
    "                        \"location_id\": \"None\"})\n",
    "        \n",
    "# Progress update each 10.000 Tweets + Timestamp\n",
    "counter=0\n",
    "\n",
    "# Path Hydrated Tweets\n",
    "fileHydrated = 'C:/Users/dennis/Desktop/TweetsCOV19ALLIDs.jsonl'\n",
    "with open(fileHydrated,encoding=\"utf8\",errors='ignore') as hydratedJSON:\n",
    "    \n",
    "    # Path to save predictions\n",
    "    filePredictions = 'C:/Users/dennis/Desktop/Carmen.csv'\n",
    "    \n",
    "    with open (filePredictions, 'w', newline='',encoding=\"utf-8\") as csvfile:   \n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        \n",
    "        for line in hydratedJSON:            \n",
    "            # Each Tweet will be predicted by its own, due to memory usage\n",
    "            locatedTweet = getLocation(line)\n",
    "            \n",
    "            # Save predictions to File\n",
    "            writer.writerow(locatedTweet.values())\n",
    "            counter = counter +1\n",
    "            \n",
    "            if(((counter % 10000)==0) or counter == 1):\n",
    "                x = datetime.datetime.now()\n",
    "                print(x.strftime(\"%X\")+\" \"+str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: 47.73%, State: 36.4%, County: 24.49%, City: 27.26%\n",
      "United States: 1745400, State 90.18%, County 62.04%, City 61.76%\n",
      "United Kingdom: 388679, State 78.75%, County 64.06%, City 58.83%\n",
      "Germany: 16817, State 42.02%, County 39.07%, City 33.86%\n",
      "France: 17346, State 38.25%, County 37.53%, City 37.52%\n",
      "Spain: 9876, State 58.75%, County 44.7%, City 41.91%\n",
      "India: 268334, State 52.85%, County 17.01%, City 44.59%\n",
      "Italy: 6840, State 39.12%, County 36.84%, City 33.85%\n"
     ]
    }
   ],
   "source": [
    "# Print coverage for Carmen predictions\n",
    "import pandas as pd\n",
    "\n",
    "# Path Carmen predictions\n",
    "pathCarmen='C:/Users/dennis/Desktop/BachelorArbeit/resultsAll/Carmen.csv'\n",
    "\n",
    "# Read Carmen predictions into dataframe, replace \"None\" with \"null\", and put \"null\" for empty cells\n",
    "df_carmen = pd.read_csv(pathCarmen, delimiter =';',names=['id','latitude',\"longitude\",\"country\",\"state\",\"county\",\"city\",\"known\",\"location_id\"])\n",
    "df_carmen = df_carmen.replace(\"None\", \"null\")\n",
    "df_carmen = df_carmen.fillna(\"null\")\n",
    "\n",
    "\n",
    "# Coverage for the whole dataset\n",
    "countAll = len(df_carmen)\n",
    "def countTweets(locationType):\n",
    "        df_region = df_carmen[df_carmen[locationType]!=\"null\"]\n",
    "        count=len(df_region)\n",
    "        return count\n",
    "\n",
    "countCountries = countTweets(\"country\")\n",
    "countState = countTweets(\"state\")\n",
    "countCounty = countTweets(\"county\")\n",
    "countCity = countTweets(\"city\")\n",
    "\n",
    "covCountries = round(((countTweets(\"country\")/countAll)*100),2)\n",
    "covState = round(((countTweets(\"state\")/countAll)*100),2)\n",
    "covCounty = round(((countTweets(\"county\")/countAll)*100),2)\n",
    "covCity = round(((countTweets(\"city\")/countAll)*100),2)\n",
    "\n",
    "print(\"Country: \"+ str(covCountries)+\"%, State: \"+str(covState)+\"%, County: \"+str(covCounty)+\"%, City: \"+str(covCity)+\"%\")\n",
    "print(\"*********************************\")\n",
    "\n",
    "\n",
    "# Coverage for specific countries\n",
    "list_countries = [\"United States\",\"United Kingdom\",\"Germany\",\"France\",\"Spain\",\"India\",\"Italy\"]\n",
    "\n",
    "def countTweets(list_countries,locationType):\n",
    "    count = {}\n",
    "    \n",
    "    # Count tweets on state,county,city level\n",
    "    if locationType != \"country\":\n",
    "        for x in list_countries:\n",
    "            df_country = df_carmen[df_carmen[\"country\"]==x]\n",
    "            #Count is equal to rows which are not \"null\" \n",
    "            df_region = df_country[df_country[locationType]!=\"null\"]\n",
    "            count[x]=len(df_region)\n",
    "        return count\n",
    "        \n",
    "    # Count tweets on country level\n",
    "    for x in list_countries:\n",
    "        df_country = df_carmen[df_carmen[locationType]==x]\n",
    "        count[x]=len(df_country)\n",
    "    return count\n",
    "\n",
    "# Calculate coverage for each country in list_countries\n",
    "countCountries = countTweets(list_countries,\"country\")\n",
    "countState = countTweets(list_countries,\"state\")\n",
    "countCounty = countTweets(list_countries,\"county\")\n",
    "countCity = countTweets(list_countries,\"city\")\n",
    "\n",
    "# Print results\n",
    "for x in list_countries:\n",
    "    percState = round(((countState[x]/countCountries[x])*100),2)\n",
    "    percCounty = round(((countCounty[x]/countCountries[x])*100),2)\n",
    "    percCity = round(((countCity[x]/countCountries[x])*100),2)\n",
    "    \n",
    "    print(x+\": \"+str(countCountries[x])+\", State \"+str(percState)+\"%, County \"+str(percCounty)+\"%, City \"+str(percCity)+\"%\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
